{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ckqvdU_kOxFe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.mkdir(\"data\")\n",
        "os.mkdir(\"data/gt\")\n",
        "os.mkdir(\"data/sat\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AJkrjo755a7E",
        "outputId": "5025081b-0aec-4391-9dca-c90fb2d55348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tifffile\n",
        "!pip install libtiff"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.6/dist-packages (2018.11.28)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from tifffile) (1.14.6)\n",
            "Requirement already satisfied: libtiff in /usr/local/lib/python3.6/dist-packages (0.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "AZUef-Pm5VO8"
      },
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mApX4yDd5VO_",
        "outputId": "cb001fcc-3a62-45aa-9dc0-1b412175a147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# u-net model with up-convolution or up-sampling and weighted binary-crossentropy as loss func\n",
        "import os\n",
        "import numpy as np\n",
        "import tifffile as tiff\n",
        "import math\n",
        "# import libtiff\n",
        "import scipy.misc\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "uCDaiihW5VPT"
      },
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wlM4z26c5VPU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "N_BANDS = 4\n",
        "N_CLASSES = 8  # Roads, Trees, Bare Soil, Rails, Buildings, Grass, Water, Pools\n",
        "CLASS_WEIGHTS = [0.2, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
        "N_EPOCHS = 150\n",
        "UPCONV = True\n",
        "PATCH_SZ = 112   # should divide by 16\n",
        "BATCH_SIZE = 150\n",
        "TRAIN_SZ = 4000  # train size\n",
        "VAL_SZ = 1000    # validation size\n",
        "loc = 'data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "11K5NaqP5VPF"
      },
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gh8ohr_P5VPH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(img):\n",
        "    min = img.min()\n",
        "    max = img.max()\n",
        "    x = 2.0 * (img - min) / (max - min) - 1.0\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lvDMs4mr_ZFe",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rowslice(image, gtimage):\n",
        "    n = math.floor(image.shape[1]/(PATCH_SZ//2))\n",
        "    w = image.shape[1]\n",
        "    rarr = range(n+1)\n",
        "    X_row = []\n",
        "    Y_row = []\n",
        "    for i in rarr[:n-1]:\n",
        "        X_row += [image[:, (PATCH_SZ//2)*i:(PATCH_SZ//2)*(i+2), :]]\n",
        "        Y_row += [gtimage[:, (PATCH_SZ//2)*i:(PATCH_SZ//2)*(i+2), :]]\n",
        "    if image.shape[1] % (PATCH_SZ//2) != 0:\n",
        "        X_row += [image[:, w-PATCH_SZ:, :]]\n",
        "        Y_row += [gtimage[:, w-PATCH_SZ:, :]]\n",
        "    return [X_row, Y_row]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7jPQFzA9_aYo",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def slice(image, gtimage):\n",
        "    m = math.floor(image.shape[0]/(PATCH_SZ//2))\n",
        "    h = image.shape[0]\n",
        "    rarr = range(m+1)\n",
        "    X = []\n",
        "    Y = []\n",
        "    for i in rarr[:m-1]:\n",
        "        [X_row, Y_row] = rowslice(image[(PATCH_SZ//2)*i:(PATCH_SZ//2)*(i+2), :, :], gtimage[(PATCH_SZ//2)*i:(PATCH_SZ//2)*(i+2), :, :])\n",
        "        for X_ in X_row:\n",
        "            X += [X_]\n",
        "        for Y_ in Y_row:\n",
        "            Y += [Y_]\n",
        "    if h % (PATCH_SZ//2) != 0:\n",
        "        [X_row, Y_row] = rowslice(image[h-PATCH_SZ:, :, :], gtimage[h-PATCH_SZ:, :, :])\n",
        "        for X_ in X_row:\n",
        "            X += [X_]\n",
        "        for Y_ in Y_row:\n",
        "            Y += [Y_]\n",
        "    return [X, Y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZUS5v4yH5VPL"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jNegdpEt5VPM"
      },
      "cell_type": "markdown",
      "source": [
        "Model Image"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qwhDRr785VPN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unet_model(n_classes=5, im_sz=160, n_channels=8, n_filters_start=32, growth_factor=2, upconv=True,\n",
        "               class_weights=[0.2, 0.3, 0.1, 0.1, 0.3]):\n",
        "    droprate=0.25\n",
        "    n_filters = n_filters_start\n",
        "    inputs = Input((im_sz, im_sz, n_channels))\n",
        "    #inputs = BatchNormalization()(inputs)\n",
        "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    #pool1 = Dropout(droprate)(pool1)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool1 = BatchNormalization()(pool1)\n",
        "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    pool2 = Dropout(droprate)(pool2)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool2 = BatchNormalization()(pool2)\n",
        "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    pool3 = Dropout(droprate)(pool3)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool3 = BatchNormalization()(pool3)\n",
        "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_0)\n",
        "    pool4_1 = MaxPooling2D(pool_size=(2, 2))(conv4_0)\n",
        "    pool4_1 = Dropout(droprate)(pool4_1)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    pool4_1 = BatchNormalization()(pool4_1)\n",
        "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_1)\n",
        "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_1)\n",
        "    pool4_2 = MaxPooling2D(pool_size=(2, 2))(conv4_1)\n",
        "    pool4_2 = Dropout(droprate)(pool4_2)\n",
        "\n",
        "    n_filters *= growth_factor\n",
        "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_2)\n",
        "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up6_1 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv5), conv4_1])\n",
        "    else:\n",
        "        up6_1 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4_1])\n",
        "    up6_1 = BatchNormalization()(up6_1)\n",
        "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_1)\n",
        "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_1)\n",
        "    conv6_1 = Dropout(droprate)(conv6_1)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up6_2 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_1), conv4_0])\n",
        "    else:\n",
        "        up6_2 = concatenate([UpSampling2D(size=(2, 2))(conv6_1), conv4_0])\n",
        "    up6_2 = BatchNormalization()(up6_2)\n",
        "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_2)\n",
        "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_2)\n",
        "    conv6_2 = Dropout(droprate)(conv6_2)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up7 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_2), conv3])\n",
        "    else:\n",
        "        up7 = concatenate([UpSampling2D(size=(2, 2))(conv6_2), conv3])\n",
        "    up7 = BatchNormalization()(up7)\n",
        "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv7)\n",
        "    conv7 = Dropout(droprate)(conv7)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up8 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv7), conv2])\n",
        "    else:\n",
        "        up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
        "    up8 = BatchNormalization()(up8)\n",
        "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv8)\n",
        "    conv8 = Dropout(droprate)(conv8)\n",
        "\n",
        "    n_filters //= growth_factor\n",
        "    if upconv:\n",
        "        up9 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv8), conv1])\n",
        "    else:\n",
        "        up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
        "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(n_classes, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    def weighted_binary_crossentropy(y_true, y_pred):\n",
        "        class_loglosses = K.mean(K.binary_crossentropy(y_true, y_pred), axis=[0, 1, 2])\n",
        "        return K.sum(class_loglosses * K.constant(class_weights))\n",
        "\n",
        "    model.compile(optimizer=Adam(), loss=weighted_binary_crossentropy)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "byR5DDeP5VPQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    return unet_model(N_CLASSES, PATCH_SZ, n_channels=N_BANDS, upconv=UPCONV, class_weights=CLASS_WEIGHTS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "U_Ydivz15VPX"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparation for Training"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zwn_e-ZL5VPY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights_path = 'weights'\n",
        "if not os.path.exists(weights_path):\n",
        "    os.makedirs(weights_path)\n",
        "weights_path += '/weights.hdf5'\n",
        "\n",
        "# all availiable ids: from \"1\" to \"14\"\n",
        "trainIds = [str(i) for i in range(1, 15)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xhIxsjIN_kbW",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = []\n",
        "Y = []\n",
        "for i in range(1, 15):\n",
        "    addri = loc+'sat/'+str(i)+'.tif'\n",
        "    addrgti = loc+'gt/'+str(i)+'.tif'\n",
        "    image = np.array(io.imread(addri))\n",
        "    gtimage = io.imread(addrgti)\n",
        "    gtimage = np.array(gtimage)\n",
        "    [X1, Y1] = slice(image, gtimage)\n",
        "#     print(image.shape,gtimage.shape)\n",
        "    X += X1\n",
        "    Y += Y1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BRVrHnc5_mUx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3a6f2920-5d99-4030-93c7-4e35ee900e33"
      },
      "cell_type": "code",
      "source": [
        "print(len(X))\n",
        "part = 75\n",
        "x_train = [X[:len(X)*part//100]]\n",
        "y_train = [Y[:len(Y)*part//100]]\n",
        "x_val = [X[len(X)*part//100:]]\n",
        "y_val = [Y[len(Y)*part//100:]]\n",
        "print(np.array(x_train).shape, np.array(y_val).shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5535\n",
            "(1, 4151, 112, 112, 4) (1, 1384, 112, 112, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rdJJVZu-5VPh"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eeuccIq55VPi",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_net():\n",
        "    print(\"start train net\")\n",
        "#     x_train, y_train = get_patches(\n",
        "#         X_DICT_TRAIN, Y_DICT_TRAIN, n_patches=TRAIN_SZ, sz=PATCH_SZ)\n",
        "#     x_val, y_val = get_patches(\n",
        "#         X_DICT_VALIDATION, Y_DICT_VALIDATION, n_patches=VAL_SZ, sz=PATCH_SZ)\n",
        "    model = get_model()\n",
        "    if os.path.isfile(weights_path):\n",
        "        model.load_weights(weights_path)\n",
        "    #model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_weights_only=True, save_best_only=True)\n",
        "    #early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "    #reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, min_lr=0.00001)\n",
        "    model_checkpoint = ModelCheckpoint(\n",
        "        weights_path, monitor='val_loss', save_best_only=True)\n",
        "    csv_logger = CSVLogger('log_unet.csv', append=True, separator=';')\n",
        "    tensorboard = TensorBoard(\n",
        "        log_dir='./tensorboard_unet/', write_graph=True, write_images=True)\n",
        "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
        "              verbose=2, shuffle=True,\n",
        "              callbacks=[model_checkpoint, csv_logger, tensorboard],\n",
        "              validation_data=(x_val, y_val))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jQwqGTml5VPl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "outputId": "a9cb9a70-8a4b-4a11-f564-8ac5a8be21ae"
      },
      "cell_type": "code",
      "source": [
        "# loadImages()\n",
        "model = train_net()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start train net\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-85b4bdc9c451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-b7aa6c47c018>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     x_val, y_val = get_patches(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         X_DICT_VALIDATION, Y_DICT_VALIDATION, n_patches=VAL_SZ, sz=PATCH_SZ)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-ba02963bc180>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATCH_SZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_BANDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupconv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUPCONV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCLASS_WEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-c0a42698a51c>\u001b[0m in \u001b[0;36munet_model\u001b[0;34m(n_classes, im_sz, n_channels, n_filters_start, growth_factor, upconv, class_weights)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mn_filters\u001b[0m \u001b[0;34m//=\u001b[0m \u001b[0mgrowth_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupconv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mup6_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv4_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mup6_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUpSampling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv4_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \"\"\"\n\u001b[0;32m--> 649\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    360\u001b[0m                              \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                              \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                              'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 6, 6, 512), (None, 7, 7, 512)]"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zu2u3tV15VPo"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zViScuXQ5VPp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(x_train, y_train, verbose=0)\n",
        "scores_val = model.evaluate(x_val, y_val, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PiDhqb0V5VPr"
      },
      "cell_type": "markdown",
      "source": [
        "## Saving the model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "F2_StRw65VPs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(os.path.join(\"weights\", \"model.json\"), \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(os.path.join(\"weights\", \"weights.hdf5\"))\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "s_Lp_gDT5VPu"
      },
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CvD27JQd5VPv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(x, model, patch_sz=160, n_classes=5):\n",
        "    img_height = x.shape[0]\n",
        "    img_width = x.shape[1]\n",
        "    n_channels = x.shape[2]\n",
        "    # make extended img so that it contains integer number of patches\n",
        "    npatches_vertical = math.ceil(img_height / patch_sz)\n",
        "    npatches_horizontal = math.ceil(img_width / patch_sz)\n",
        "    extended_height = patch_sz * npatches_vertical\n",
        "    extended_width = patch_sz * npatches_horizontal\n",
        "    ext_x = np.zeros(shape=(extended_height, extended_width,\n",
        "                            n_channels), dtype=np.float32)\n",
        "    # fill extended image with mirrors:\n",
        "    ext_x[:img_height, :img_width, :] = x\n",
        "    for i in range(img_height, extended_height):\n",
        "        ext_x[i, :, :] = ext_x[2 * img_height - i - 1, :, :]\n",
        "    for j in range(img_width, extended_width):\n",
        "        ext_x[:, j, :] = ext_x[:, 2 * img_width - j - 1, :]\n",
        "\n",
        "    # now we assemble all patches in one array\n",
        "    patches_list = []\n",
        "    for i in range(0, npatches_vertical):\n",
        "        for j in range(0, npatches_horizontal):\n",
        "            x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
        "            y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
        "            patches_list.append(ext_x[x0:x1, y0:y1, :])\n",
        "    # model.predict() needs numpy array rather than a list\n",
        "    patches_array = np.asarray(patches_list)\n",
        "    # predictions:\n",
        "    patches_predict = model.predict(patches_array, batch_size=4)\n",
        "    prediction = np.zeros(\n",
        "        shape=(extended_height, extended_width, n_classes), dtype=np.float32)\n",
        "    for k in range(patches_predict.shape[0]):\n",
        "        i = k // npatches_horizontal\n",
        "        j = k % npatches_vertical\n",
        "        x0, x1 = i * patch_sz, (i + 1) * patch_sz\n",
        "        y0, y1 = j * patch_sz, (j + 1) * patch_sz\n",
        "        prediction[x0:x1, y0:y1, :] = patches_predict[k, :, :, :]\n",
        "    return prediction[:img_height, :img_width, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bxN6OJQX5VPx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def picture_from_mask(mask, threshold=0):\n",
        "    colors = {\n",
        "        0: [150, 150, 150],  # Roads\n",
        "        1: [223, 194, 125],  # Trees\n",
        "        2: [27, 120, 55],    # Bare Soil\n",
        "        3: [166, 219, 160],  # Building\n",
        "        4: [116, 173, 209]   # Grass\n",
        "        5: [169,169,169]     # Water\n",
        "        6: [0,191,255]       # Pools\n",
        "    }\n",
        "    z_order = {\n",
        "        1: 3,\n",
        "        2: 4,\n",
        "        3: 5,\n",
        "        4: 6,\n",
        "        5: 7,\n",
        "        6: 8,\n",
        "        7: 1,\n",
        "        8: 2\n",
        "    }\n",
        "    pict = 255*np.ones(shape=(3, mask.shape[1], mask.shape[2]), dtype=np.uint8)\n",
        "    for i in range(1, 6):\n",
        "        cl = z_order[i]\n",
        "        for ch in range(3):\n",
        "            pict[ch, :, :][mask[cl, :, :] > threshold] = colors[cl][ch]\n",
        "    return pict\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "v8VJKgfc5VPz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "jsonFile = open(os.path.join(\"weights\", \"model.json\"), 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lnl96a6c5VP3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_id = '4'\n",
        "img = normalize(tiff.imread('data/sat/{}.tif'.format(test_id)).transpose([1, 2, 0]))   # make channels last\n",
        "\n",
        "for i in range(7):\n",
        "    if i == 0:  # reverse first dimension\n",
        "        mymat = predict(img[::-1, :, :], model, patch_sz=PATCH_SZ,\n",
        "                        n_classes=N_CLASSES).transpose([2, 0, 1])\n",
        "        #print(mymat[0][0][0], mymat[3][12][13])\n",
        "        print(\"Case 1\", img.shape, mymat.shape)\n",
        "    elif i == 1:    # reverse second dimension\n",
        "        temp = predict(img[:, ::-1, :], model, patch_sz=PATCH_SZ,\n",
        "                       n_classes=N_CLASSES).transpose([2, 0, 1])\n",
        "        #print(temp[0][0][0], temp[3][12][13])\n",
        "        print(\"Case 2\", temp.shape, mymat.shape)\n",
        "        mymat = np.mean(np.array([temp[:, ::-1, :], mymat]), axis=0)\n",
        "    elif i == 2:    # transpose(interchange) first and second dimensions\n",
        "        temp = predict(img.transpose(\n",
        "            [1, 0, 2]), model, patch_sz=PATCH_SZ, n_classes=N_CLASSES).transpose([2, 0, 1])\n",
        "        #print(temp[0][0][0], temp[3][12][13])\n",
        "        print(\"Case 3\", temp.shape, mymat.shape)\n",
        "        mymat = np.mean(np.array([temp.transpose(0, 2, 1), mymat]), axis=0)\n",
        "    elif i == 3:\n",
        "        temp = predict(np.rot90(img, 1), model,\n",
        "                       patch_sz=PATCH_SZ, n_classes=N_CLASSES)\n",
        "        #print(temp.transpose([2,0,1])[0][0][0], temp.transpose([2,0,1])[3][12][13])\n",
        "        print(\"Case 4\", temp.shape, mymat.shape)\n",
        "        mymat = np.mean(\n",
        "            np.array([np.rot90(temp, -1).transpose([2, 0, 1]), mymat]), axis=0)\n",
        "    elif i == 4:\n",
        "        temp = predict(np.rot90(img, 2), model,\n",
        "                       patch_sz=PATCH_SZ, n_classes=N_CLASSES)\n",
        "        #print(temp.transpose([2,0,1])[0][0][0], temp.transpose([2,0,1])[3][12][13])\n",
        "        print(\"Case 5\", temp.shape, mymat.shape)\n",
        "        mymat = np.mean(\n",
        "            np.array([np.rot90(temp, -2).transpose([2, 0, 1]), mymat]), axis=0)\n",
        "    elif i == 5:\n",
        "        temp = predict(np.rot90(img, 3), model,\n",
        "                       patch_sz=PATCH_SZ, n_classes=N_CLASSES)\n",
        "        #print(temp.transpose([2,0,1])[0][0][0], temp.transpose([2,0,1])[3][12][13])\n",
        "        print(\"Case 6\", temp.shape, mymat.shape)\n",
        "        mymat = np.mean(\n",
        "            np.array([np.rot90(temp, -3).transpose(2, 0, 1), mymat]), axis=0)\n",
        "    else:\n",
        "        temp = predict(img, model, patch_sz=PATCH_SZ,\n",
        "                       n_classes=N_CLASSES).transpose([2, 0, 1])\n",
        "        #print(temp[0][0][0], temp[3][12][13])\n",
        "        print(\"Case 7\", temp.shape, mymat.shape)\n",
        "        mymat = np.mean(np.array([temp, mymat]), axis=0)\n",
        "\n",
        "#print(mymat[0][0][0], mymat[3][12][13])\n",
        "map = picture_from_mask(mymat, 0.5)\n",
        "# mask = predict(img, model, patch_sz=PATCH_SZ, n_classes=N_CLASSES).transpose([2,0,1])  # make channels first\n",
        "#map = picture_from_mask(mask, 0.5)\n",
        "\n",
        "#tiff.imsave('result.tif', (255*mask).astype('uint8'))\n",
        "tiff.imsave('result.tif', (255*mymat).astype('uint8'))\n",
        "tiff.imsave('map.tif', map)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}